{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Class Classification with DistilBERT"
      ],
      "metadata": {
        "id": "4nl2tkvtbAHI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJKww_KP68Pe",
        "outputId": "9e4e68fc-4ab9-4927-bf26-e645139669e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dataset\n",
        "!pip install transformers\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFQJpQEF9Iba",
        "outputId": "86b463ec-c972-4fcc-e58e-b46d82cb655b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dataset in /usr/local/lib/python3.8/dist-packages (1.5.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.4.44)\n",
            "Requirement already satisfied: alembic>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.8.1)\n",
            "Requirement already satisfied: banal>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from dataset) (1.0.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (4.13.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (5.10.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=0.6.2->dataset) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.2->dataset) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=0.6.2->dataset) (3.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "69kqT3O58UGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Bert/data.csv')  \n",
        "shuffled_df = df.sample(frac=1)\n",
        "shuffled_df.to_csv(\"shuffled_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "_vHrR56f8JPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('shuffled_data.csv')  "
      ],
      "metadata": {
        "id": "zayNNaSM8dbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "WV94a-EB8fDA",
        "outputId": "65df314c-08e4-4361-cb26-8a4c4dca9a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                review_id                 user_id             business_id  \\\n",
              "0  D5jAKP4AEuOPiCRr4sbJWw  VaUgmU6O7KQK2WCfI_eboQ  iSHKYbQfB2q6sGnd7AD2_A   \n",
              "1  9Vi_TzSq_t80KjIUoRqpeg  pXGJIcj8qHEUb3IhunQ-Qw  aIflpZXlmofFGelTlqgGEQ   \n",
              "2  ww6FLkCBWbzxRSRvUsLPrw  gAcz_T0JKVmXDWkFehJigQ  KP5OncF2jhT7_J1phHPPww   \n",
              "3  k4xVggYniF-HzMzGLHy4dQ  UQFE3BT1rsIYrcDvu_XVow  diwwt5QBU3-Thig9SVlsOA   \n",
              "4  bYq7Mw3DDNTg-Jo1dhM8JA  Fa2-VD8cqcn98vqciVn3Gw  ixPTo6Hum7nNZ7A4VPhTXg   \n",
              "\n",
              "   stars  useful  funny  cool  \\\n",
              "0      4       0      0     0   \n",
              "1      3       0      0     0   \n",
              "2      2       1      1     1   \n",
              "3      3       0      0     0   \n",
              "4      3       0      0     0   \n",
              "\n",
              "                                                text                 date  \n",
              "0  We've tried most of the Chinese restaurants in...  2015-01-04 19:47:44  \n",
              "1  Potstickers were good but the lo-mein my boyfr...  2018-08-25 04:43:00  \n",
              "2  Had dinner here on a recent Friday evening.  G...  2015-05-26 22:31:48  \n",
              "3  Jersey Shore meets Reno. \\r\\n\\r\\nSurprisingly ...  2012-03-07 19:00:13  \n",
              "4  Decent, quick, and relatively friendly service...  2013-05-11 23:56:42  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e5b3e3b-bcb3-4fad-8152-fd8b6c3236e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>useful</th>\n",
              "      <th>funny</th>\n",
              "      <th>cool</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D5jAKP4AEuOPiCRr4sbJWw</td>\n",
              "      <td>VaUgmU6O7KQK2WCfI_eboQ</td>\n",
              "      <td>iSHKYbQfB2q6sGnd7AD2_A</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>We've tried most of the Chinese restaurants in...</td>\n",
              "      <td>2015-01-04 19:47:44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9Vi_TzSq_t80KjIUoRqpeg</td>\n",
              "      <td>pXGJIcj8qHEUb3IhunQ-Qw</td>\n",
              "      <td>aIflpZXlmofFGelTlqgGEQ</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Potstickers were good but the lo-mein my boyfr...</td>\n",
              "      <td>2018-08-25 04:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ww6FLkCBWbzxRSRvUsLPrw</td>\n",
              "      <td>gAcz_T0JKVmXDWkFehJigQ</td>\n",
              "      <td>KP5OncF2jhT7_J1phHPPww</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Had dinner here on a recent Friday evening.  G...</td>\n",
              "      <td>2015-05-26 22:31:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k4xVggYniF-HzMzGLHy4dQ</td>\n",
              "      <td>UQFE3BT1rsIYrcDvu_XVow</td>\n",
              "      <td>diwwt5QBU3-Thig9SVlsOA</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Jersey Shore meets Reno. \\r\\n\\r\\nSurprisingly ...</td>\n",
              "      <td>2012-03-07 19:00:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bYq7Mw3DDNTg-Jo1dhM8JA</td>\n",
              "      <td>Fa2-VD8cqcn98vqciVn3Gw</td>\n",
              "      <td>ixPTo6Hum7nNZ7A4VPhTXg</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Decent, quick, and relatively friendly service...</td>\n",
              "      <td>2013-05-11 23:56:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e5b3e3b-bcb3-4fad-8152-fd8b6c3236e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e5b3e3b-bcb3-4fad-8152-fd8b6c3236e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e5b3e3b-bcb3-4fad-8152-fd8b6c3236e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = ['review_id','user_id','business_id','useful','funny','cool','date']\n",
        "df = df.drop(drop_columns, axis=1)"
      ],
      "metadata": {
        "id": "FetLx34y8vDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aVfAfjjR8x0z",
        "outputId": "d3017637-6e2d-4551-d0b1-11b8279264f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stars                                               text\n",
              "0      4  We've tried most of the Chinese restaurants in...\n",
              "1      3  Potstickers were good but the lo-mein my boyfr...\n",
              "2      2  Had dinner here on a recent Friday evening.  G...\n",
              "3      3  Jersey Shore meets Reno. \\r\\n\\r\\nSurprisingly ...\n",
              "4      3  Decent, quick, and relatively friendly service..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28683052-e221-496e-9f4c-b587295984b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>We've tried most of the Chinese restaurants in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Potstickers were good but the lo-mein my boyfr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Had dinner here on a recent Friday evening.  G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Jersey Shore meets Reno. \\r\\n\\r\\nSurprisingly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Decent, quick, and relatively friendly service...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28683052-e221-496e-9f4c-b587295984b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28683052-e221-496e-9f4c-b587295984b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28683052-e221-496e-9f4c-b587295984b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "tuxerLKw88av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preapre dataset as input for Bert\n",
        "class Ds(Dataset):\n",
        "  def __init__(self, df, tokenizer):\n",
        "    self.df=df\n",
        "    self.tokenizer=tokenizer\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  def __getitem__(self,index):\n",
        "    item=self.df.iloc[index]\n",
        "    text=item[\"text\"]\n",
        "    star=item[\"stars\"]\n",
        "    label=[0.,0.,0.,0.,0.]\n",
        "    label[star-1]=1.\n",
        "    tokens=self.tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=300, padding=\"max_length\")\n",
        "    return {\"input_ids\":torch.squeeze(tokens.input_ids), \"attention_mask\":torch.squeeze(tokens.attention_mask),\"labels\":label}\n",
        "    "
      ],
      "metadata": {
        "id": "6E-iDz039jjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize data with DistilBertTokenizer\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AutoConfig\n",
        "config=AutoConfig.from_pretrained(\"distilbert-base-uncased\")\n",
        "config.num_labels=5\n",
        "print(config.num_labels)\n",
        "tokenzier=DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "print(config)\n",
        "model=DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", problem_type=\"multi_label_classification\", num_labels=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOj0cd6rAPKn",
        "outputId": "a4c0a6f5-8edf-4916-de3f-c8eee1b81a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"problem_type\": \"multi_label_classification\",\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=Ds(df, tokenzier)"
      ],
      "metadata": {
        "id": "M-q3fDOgAMC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXlSEu4ATmya",
        "outputId": "32f939fb-2cd7-4984-c4b3-74ffbf491459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([  101, 18911, 26348,  2545,  2020,  2204,  2021,  1996,  8840,  1011,\n",
              "         24182,  2026,  6898,  2288,  4694,  1005,  1056,  2130, 12984,  1012,\n",
              "          2027,  2020,  2074,  2524,  4895,  3597, 23461, 27130,  1998,  2070,\n",
              "         23582,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': [0.0, 0.0, 1.0, 0.0, 0.0]}"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze Bert layers\n",
        "for name, param in model.named_parameters():\n",
        "  #print(name)\n",
        "  if name.startswith(\"dis\"):\n",
        "    param.requires_grad=False\n",
        "  else:\n",
        "    print(name)\n",
        "    param.requires_grad=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63KNLqDo9U6j",
        "outputId": "48a129a1-4f3a-40cc-9042-2394d08ff244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre_classifier.weight\n",
            "pre_classifier.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\") "
      ],
      "metadata": {
        "id": "UoPT9bndDP0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcuate accuracy score \n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "  logits,labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  labels = np.argmax(labels, axis=-1)\n",
        "  return metric.compute(predictions=predictions, references=labels) \n",
        "\n",
        "'''\n",
        "# Calculate precision, recall, f1, accuracy score \n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "def custom_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    labels = np.argmax(labels, axis=-1)\n",
        "\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"micro\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"micro\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "I6U_N1LoEP01",
        "outputId": "08417405-5d9d-46b4-c188-035bbb2b002b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\nimport numpy as np\\nfrom datasets import load_metric\\n\\ndef custom_metrics(eval_pred):\\n    metric1 = load_metric(\"precision\")\\n    metric2 = load_metric(\"recall\")\\n    metric3 = load_metric(\"f1\")\\n    metric4 = load_metric(\"accuracy\")\\n    \\n    logits, labels = eval_pred\\n    predictions = np.argmax(logits, axis=-1)\\n    labels = np.argmax(labels, axis=-1)\\n\\n    precision = metric1.compute(predictions=predictions, references=labels, average=\"micro\")[\"precision\"]\\n    recall = metric2.compute(predictions=predictions, references=labels, average=\"micro\")[\"recall\"]\\n    f1 = metric3.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\\n    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\\n\\n    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy}\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\""
      ],
      "metadata": {
        "id": "H9YsfQWeEuQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fine tune the model \n",
        "from transformers import TrainingArguments, Trainer\n",
        "training_args=TrainingArguments(output_dir=\"/content/drive/MyDrive/Bert/\",\n",
        "                                evaluation_strategy=\"epoch\",\n",
        "                                num_train_epochs=50,\n",
        "                                per_device_train_batch_size=64,\n",
        "                                per_device_eval_batch_size=64,\n",
        "                                save_steps=1e5,\n",
        "                                weight_decay=0.01)  #weight_delay can be change \n",
        "\n",
        "#maybe add optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AX4cK7cExJ1",
        "outputId": "09c07c2d-b797-4b80-9b08-1c2559ccb965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "train_ds,val_ds=torch.utils.data.random_split(ds, [9000, 1000])\n",
        "data_collator=DataCollatorWithPadding(tokenizer=tokenzier)"
      ],
      "metadata": {
        "id": "ZGmCYUtbF2pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        "    #compute_metrics=custom_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "VIh9U7SbGKxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pne3FphIHIEj",
        "outputId": "c2fbf578-61c5-4486-b400-48dfb7d5d94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 9000\n",
            "  Num Epochs = 50\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7050\n",
            "  Number of trainable parameters = 594437\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7050' max='7050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7050/7050 1:36:52, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.475492</td>\n",
              "      <td>0.491000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.438635</td>\n",
              "      <td>0.506000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.411535</td>\n",
              "      <td>0.501000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.461300</td>\n",
              "      <td>0.398109</td>\n",
              "      <td>0.498000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.461300</td>\n",
              "      <td>0.389115</td>\n",
              "      <td>0.528000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.461300</td>\n",
              "      <td>0.383135</td>\n",
              "      <td>0.531000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.461300</td>\n",
              "      <td>0.380193</td>\n",
              "      <td>0.535000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>0.375721</td>\n",
              "      <td>0.529000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>0.373867</td>\n",
              "      <td>0.538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.393700</td>\n",
              "      <td>0.372174</td>\n",
              "      <td>0.535000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.377700</td>\n",
              "      <td>0.369652</td>\n",
              "      <td>0.543000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.377700</td>\n",
              "      <td>0.368710</td>\n",
              "      <td>0.538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.377700</td>\n",
              "      <td>0.367216</td>\n",
              "      <td>0.553000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.377700</td>\n",
              "      <td>0.365830</td>\n",
              "      <td>0.546000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.370800</td>\n",
              "      <td>0.364949</td>\n",
              "      <td>0.548000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.370800</td>\n",
              "      <td>0.363541</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.370800</td>\n",
              "      <td>0.362800</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.365300</td>\n",
              "      <td>0.363341</td>\n",
              "      <td>0.545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.365300</td>\n",
              "      <td>0.361369</td>\n",
              "      <td>0.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.365300</td>\n",
              "      <td>0.360087</td>\n",
              "      <td>0.559000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.365300</td>\n",
              "      <td>0.360355</td>\n",
              "      <td>0.547000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.362700</td>\n",
              "      <td>0.359363</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.362700</td>\n",
              "      <td>0.358834</td>\n",
              "      <td>0.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.362700</td>\n",
              "      <td>0.358434</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.359000</td>\n",
              "      <td>0.358434</td>\n",
              "      <td>0.544000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.359000</td>\n",
              "      <td>0.357633</td>\n",
              "      <td>0.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.359000</td>\n",
              "      <td>0.358336</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.359000</td>\n",
              "      <td>0.357936</td>\n",
              "      <td>0.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.356700</td>\n",
              "      <td>0.357367</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.356700</td>\n",
              "      <td>0.356864</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.356700</td>\n",
              "      <td>0.356372</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.356517</td>\n",
              "      <td>0.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.355552</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.355428</td>\n",
              "      <td>0.553000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.356480</td>\n",
              "      <td>0.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.355443</td>\n",
              "      <td>0.552000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.354901</td>\n",
              "      <td>0.557000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.355048</td>\n",
              "      <td>0.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.355000</td>\n",
              "      <td>0.354929</td>\n",
              "      <td>0.553000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.352600</td>\n",
              "      <td>0.354553</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.352600</td>\n",
              "      <td>0.354780</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.352600</td>\n",
              "      <td>0.354427</td>\n",
              "      <td>0.556000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.352800</td>\n",
              "      <td>0.354705</td>\n",
              "      <td>0.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.352800</td>\n",
              "      <td>0.354931</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.352800</td>\n",
              "      <td>0.354272</td>\n",
              "      <td>0.555000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.352800</td>\n",
              "      <td>0.354406</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.351600</td>\n",
              "      <td>0.354218</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.351600</td>\n",
              "      <td>0.354221</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.351600</td>\n",
              "      <td>0.354232</td>\n",
              "      <td>0.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.351300</td>\n",
              "      <td>0.354265</td>\n",
              "      <td>0.555000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7050, training_loss=0.36889116003158245, metrics={'train_runtime': 5812.9472, 'train_samples_per_second': 77.413, 'train_steps_per_second': 1.213, 'total_flos': 3.492979605e+16, 'train_loss': 0.36889116003158245, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dl=DataLoader(val_ds)"
      ],
      "metadata": {
        "id": "gS5oIOXADsI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate accuracy per class/star\n",
        "totalcount=[0,0,0,0,0]\n",
        "totalcorrect=[0,0,0,0,0]\n",
        "for i in dl:\n",
        "  label=i[\"labels\"]\n",
        "  input_ids=i[\"input_ids\"].to(\"cuda\")\n",
        "  attention_mask=i[\"attention_mask\"].to(\"cuda\")\n",
        "  lo=model(input_ids, attention_mask).logits[0]\n",
        "  lo=lo.cpu()\n",
        "  lo=lo.detach().numpy()\n",
        "  prediction = np.argmax(lo)\n",
        "  label = np.argmax(label, axis=-1)\n",
        "  totalcount[label]=totalcount[label]+1\n",
        "  if label == prediction: \n",
        "    totalcorrect[label]=totalcorrect[label]+1\n",
        "accuracy_based_class=torch.tensor(totalcorrect)/torch.tensor(totalcount)\n",
        "print(accuracy_based_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMPi3A1aBvy8",
        "outputId": "5dd0ad08-d0b5-45aa-c50e-4671c4848696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:43: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7716, 0.3868, 0.4369, 0.3988, 0.7642])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(totalcount)\n",
        "print(totalcorrect)\n",
        "print(accuracy_based_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSGGNyQEGA6C",
        "outputId": "a30c6bdc-aafa-41eb-f614-4d651ccaca69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[197, 212, 206, 173, 212]\n",
            "[152, 82, 90, 69, 162]\n",
            "tensor([0.7716, 0.3868, 0.4369, 0.3988, 0.7642])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "20KHy8ZxErQ4",
        "outputId": "61f52b0b-e703-4d37-a6fd-e9a7b3cf4b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 03:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.35426533222198486,\n",
              " 'eval_accuracy': 0.555,\n",
              " 'eval_runtime': 11.5122,\n",
              " 'eval_samples_per_second': 86.864,\n",
              " 'eval_steps_per_second': 1.39,\n",
              " 'epoch': 50.0}"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    }
  ]
}