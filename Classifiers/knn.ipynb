{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMgzC770N-KV",
        "outputId": "fba3b009-55e8-44de-dae6-f42b04a4b7b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rpHFiPEOCkH",
        "outputId": "51cdf45d-98b3-4bf3-c10d-340f0423c0ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd nlpProject/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it-Sh9v5OGyq",
        "outputId": "9f7c40bf-b5a3-482b-c182-1d13b812ab7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlpProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd filter_programs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmdBVQ3kOIb5",
        "outputId": "25653988-1abf-4988-a90c-7d3830158335"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlpProject/filter_programs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg_ll6REOKyN",
        "outputId": "599a69ef-a37f-4b11-8187-b96ccf47bfd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9RV9U1EOaYn",
        "outputId": "f4a0b64c-10e8-434c-e03d-28187ac3e78f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OQA4kwKpOcsW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/nlpProject/all_reviews.csv')\n",
        "shuffled_df = df.sample(frac =1)\n",
        "shuffled_df.to_csv(\"shuffled_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "_Oukyt21OeWg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.corpus import stopwords\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/nlpProject/all_reviews.csv')\n",
        "shuffled_df = df.sample(frac =1)\n",
        "shuffled_df.to_csv(\"shuffled_data.csv\", index=False)\n",
        "\n",
        "stops = stopwords.words('english')\n",
        "punct = [\"'\", \".\", \",\", '\"', \";\", \"?\", \"!\", \"-\", \"-\", \"(\", \")\", \"*\", \"/\", \":\", \"~\"]\n",
        "\n",
        "def get_data(name, answer):\n",
        "  alltext = \"\" \n",
        "  toksents = []  \n",
        "  stars = []\n",
        "  all_files = glob.glob(\"../json_data/tokenize/first_10k/\" + name + \"/*\")\n",
        "  for file in all_files:\n",
        "    f = open(file)\n",
        "    data = json.loads(f.read().rstrip())\n",
        "    f.close()\n",
        "    allsent = []\n",
        "    for review in data:\n",
        "      sent = review[\"text\"]\n",
        "      allsent = sent_tokenize(sent)\n",
        "      for w in allsent:\n",
        "        if(w not in stops):\n",
        "          toksents.append(nltk.word_tokenize(w))\n",
        "          stars.append(review['stars'])\n",
        "  if(answer == True):\n",
        "    return(toksents)\n",
        "  else:\n",
        "    return(stars)\n",
        "def get_all_data(answer):\n",
        "  alltext = \"\" \n",
        "  toksents = []  \n",
        "  stars = []\n",
        "  f = open(\"../json_data/tokenize/first_10k/all_reviews.json\")\n",
        "  data = json.loads(f.read().rstrip())\n",
        "  f.close()\n",
        "  allsent = []\n",
        "  for review in data:\n",
        "    sent = review[\"text\"]\n",
        "    allsent = sent_tokenize(sent)\n",
        "    for w in allsent:\n",
        "      if(w not in stops):\n",
        "        toksents.append(nltk.word_tokenize(w))\n",
        "        stars.append(review['stars'])\n",
        "  if(answer == True):\n",
        "    return(toksents)\n",
        "  else:\n",
        "    return(stars)\n",
        "def get_vectors(name):\n",
        "  vectors = []\n",
        "  data = get_data(name, True)\n",
        "  model = Word2Vec(data, window=5, min_count=3, workers=4)\n",
        "  for d in data:\n",
        "    totvec = np.zeros(100)\n",
        "    for w in d:\n",
        "      if w.lower() in model:\n",
        "        totvec = totvec + model[w.lower()]\n",
        "    vectors.append(totvec)\n",
        "  return vectors"
      ],
      "metadata": {
        "id": "aWWI1iFtPgVM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd \n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "def knn():\n",
        "  knn = KNeighborsClassifier()\n",
        "  #call it something other than model\n",
        "  knn.fit(get_vectors(\"train\"), get_data(\"train\", False))\n",
        "  expected = get_data(\"test\", False)\n",
        "  predicted = knn.predict(get_vectors(\"test\"))\n",
        "  print(metrics.classification_report(expected, predicted))\n",
        "  print(metrics.confusion_matrix(expected, predicted))\n",
        "knn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt7hi7jyOf9I",
        "outputId": "d785ae36-02c8-4eea-fb7f-098e0283b1a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n",
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.22      0.48      0.30      3388\n",
            "         2.0       0.20      0.07      0.10      3465\n",
            "         3.0       0.23      0.18      0.20      3293\n",
            "         4.0       0.19      0.13      0.16      3126\n",
            "         5.0       0.18      0.17      0.18      2613\n",
            "\n",
            "    accuracy                           0.21     15885\n",
            "   macro avg       0.20      0.21      0.19     15885\n",
            "weighted avg       0.20      0.21      0.19     15885\n",
            "\n",
            "[[1629  215  551  472  521]\n",
            " [1661  229  551  471  553]\n",
            " [1508  261  604  422  498]\n",
            " [1419  243  560  415  489]\n",
            " [1169  202  415  371  456]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def svc():\n",
        "  svc = LinearSVC()\n",
        "  svc.fit(get_vectors(\"train\"), get_data(\"train\", False))\n",
        "  expected = get_data(\"test\", False)\n",
        "  predicted = svc.predict(get_vectors(\"test\"))\n",
        "  print(metrics.classification_report(expected, predicted))\n",
        "  print(metrics.confusion_matrix(expected, predicted))\n",
        "svc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcrsXCRJOiEi",
        "outputId": "d15c539b-3114-40a3-a56f-baceaf43355e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.21      0.93      0.34      3388\n",
            "         2.0       0.20      0.04      0.07      3465\n",
            "         3.0       0.25      0.00      0.00      3293\n",
            "         4.0       0.00      0.00      0.00      3126\n",
            "         5.0       0.00      0.00      0.00      2613\n",
            "\n",
            "    accuracy                           0.21     15885\n",
            "   macro avg       0.13      0.20      0.08     15885\n",
            "weighted avg       0.14      0.21      0.09     15885\n",
            "\n",
            "[[3167  214    0    0    7]\n",
            " [3310  151    2    0    2]\n",
            " [3157  135    1    0    0]\n",
            " [2998  127    1    0    0]\n",
            " [2503  110    0    0    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dt():\n",
        "  dt = tree.DecisionTreeClassifier()\n",
        "  dt.fit(get_vectors(\"train\"), get_data(\"train\", False))\n",
        "  expected = get_data(\"test\", False)\n",
        "  predicted = dt.predict(get_vectors(\"test\"))\n",
        "  print(metrics.classification_report(expected, predicted))\n",
        "  print(metrics.confusion_matrix(expected, predicted))\n",
        "dt()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dq3wFl3Pnkt",
        "outputId": "a08a221b-93e6-4392-90ec-eb74cedb7043"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n",
            "<ipython-input-11-197fc19ca984>:63: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if w.lower() in model:\n",
            "<ipython-input-11-197fc19ca984>:64: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  totvec = totvec + model[w.lower()]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.25      0.04      0.07      3388\n",
            "         2.0       0.21      0.04      0.07      3465\n",
            "         3.0       0.17      0.09      0.12      3293\n",
            "         4.0       0.20      0.71      0.31      3126\n",
            "         5.0       0.20      0.15      0.17      2613\n",
            "\n",
            "    accuracy                           0.20     15885\n",
            "   macro avg       0.21      0.21      0.15     15885\n",
            "weighted avg       0.21      0.20      0.14     15885\n",
            "\n",
            "[[ 143  166  403 2268  408]\n",
            " [ 136  139  388 2381  421]\n",
            " [ 101  124  306 2390  372]\n",
            " [ 100  110  379 2204  333]\n",
            " [  94  113  364 1652  390]]\n"
          ]
        }
      ]
    }
  ]
}